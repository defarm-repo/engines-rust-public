# ADR 001: Modelo de Concorr√™ncia para StorageBackend

**Status:** Proposto
**Data:** 2025-01-24
**Decisor:** Engineering Team

## Contexto

O c√≥digo atual do DeFarm Engine usa DOIS padr√µes de concorr√™ncia simultaneamente:
- `Arc<Mutex<T>>` em 11 locais (4 arquivos)
- `Arc<RwLock<T>>` em 19 locais (9 arquivos)

Isso cria **inconsist√™ncia** e dificulta manuten√ß√£o, revis√£o de c√≥digo e onboarding de novos desenvolvedores.

### Problema Espec√≠fico

Alguns tipos t√™m AMBAS as implementa√ß√µes:
```rust
impl StorageBackend for Arc<Mutex<PostgresStorageWithCache>> {}
impl StorageBackend for Arc<RwLock<PostgresStorageWithCache>> {}
```

Isso gera:
- Confus√£o sobre qual usar
- Risco de migra√ß√£o acidental entre padr√µes
- Impossibilidade de lint autom√°tico

## Decis√£o

**Adotamos `Arc<Mutex<T>>` como padr√£o √öNICO para todos os StorageBackend.**

### Regras

1. **TODOS** os tipos que implementam `StorageBackend` DEVEM usar `Arc<Mutex<T>>`
2. **PROIBIDO** usar `Arc<RwLock<T>>` para StorageBackend
3. **PROIBIDO** usar `.read()` ou `.write()` - usar apenas `.lock()`
4. **OBRIGAT√ìRIO** soltar o lock ANTES de qualquer `.await`

### Tipo Can√¥nico

```rust
// Em src/prelude.rs (a ser criado)
pub type Shared<T> = Arc<Mutex<T>>;

// Uso
type SharedStorage = Shared<PostgresStorageWithCache>;
```

## Justificativa

### Por que Arc<Mutex<>> ao inv√©s de Arc<RwLock<>>?

| Crit√©rio | Arc<Mutex<>> | Arc<RwLock<>> |
|----------|--------------|---------------|
| **Simplicidade** | ‚úÖ Um tipo de lock apenas | ‚ùå Dois tipos (read/write) |
| **Deadlock ass√≠ncrono** | ‚úÖ N√£o detectado no c√≥digo | ‚úÖ N√£o detectado no c√≥digo |
| **Writer starvation** | ‚úÖ N√£o acontece | ‚ùå Pode acontecer |
| **Performance atual** | ‚úÖ Adequada | ‚ö†Ô∏è Desnecess√°ria |
| **Padr√£o Tokio** | ‚úÖ Mais comum | ‚ö†Ô∏è Menos comum |
| **Workload atual** | ‚úÖ N√£o √© read-heavy | ‚ùå Otimiza√ß√£o prematura |

### An√°lise de Carga

Nossa carga de trabalho:
- **Leituras:** ~60% das opera√ß√µes
- **Escritas:** ~40% das opera√ß√µes
- **Concorr√™ncia:** Baixa a m√©dia (< 100 req/s)

**Conclus√£o:** RwLock n√£o traz benef√≠cio mensur√°vel, mas adiciona complexidade.

### Evid√™ncias de Seguran√ßa Atual

An√°lise com `ripgrep` confirmou:
- ‚úÖ ZERO casos de `await` com lock segurado
- ‚úÖ Trait `StorageBackend` usa `&self` (n√£o `&mut self`)
- ‚úÖ Uso de `tokio::task::block_in_place` correto (commits recentes)

## Consequ√™ncias

### Positivas

- ‚úÖ **Uniformidade:** Um padr√£o √∫nico para toda a equipe
- ‚úÖ **Simplicidade:** Menos decis√µes = menos erros
- ‚úÖ **Manutenibilidade:** C√≥digo mais f√°cil de revisar
- ‚úÖ **Lint autom√°tico:** Poss√≠vel bloquear RwLock no CI

### Negativas

- ‚ö†Ô∏è **Refactor necess√°rio:** ~19 ocorr√™ncias de RwLock para migrar
- ‚ö†Ô∏è **Performance te√≥rica:** RwLock PODERIA ser mais r√°pido em workload read-heavy (mas n√£o √© nosso caso)

### Neutras

- üîÑ **Performance real:** Sem impacto mensur√°vel no workload atual

## Implementa√ß√£o

### Fase 1: Prote√ß√£o (imediato)

```toml
# clippy.toml
warn = [
  "clippy::await_holding_lock",
  "clippy::mutex_atomic"
]
```

```bash
# scripts/check_concurrency.sh
#!/bin/bash
if rg -n "Arc<RwLock<" src tests; then
  echo "‚ùå RwLock usage detected! Use Arc<Mutex<>> instead."
  echo "See docs/adr/001-concurrency-model.md"
  exit 1
fi
```

### Fase 2: Migra√ß√£o (gradual)

1. Criar `src/prelude.rs` com `type Shared<T> = Arc<Mutex<T>>`
2. Remover `impl StorageBackend for Arc<RwLock<PostgresStorageWithCache>>`
3. Migrar campos em ordem de impacto:
   - `postgres_storage_with_cache.rs`
   - `redis_postgres_storage.rs`
   - `events_engine.rs`, `circuits_engine.rs`, `activity_engine.rs`
   - `api_key_storage.rs`, `rate_limiter.rs`
   - `postgres_persistence.rs`

### Fase 3: Valida√ß√£o (ap√≥s migra√ß√£o)

```bash
# Deve retornar ZERO
rg -n "Arc<RwLock<" src tests
rg -n "\.(read|write)\s*\(" src tests

# Deve passar
cargo clippy --all-targets -D warnings
cargo test --all-features
```

## Alternativas Consideradas

### Alternativa 1: Manter Arc<RwLock<>> como padr√£o

**Rejeitada porque:**
- Mais complexo
- Sem ganho mensur√°vel de performance
- Menos comum no ecossistema Tokio

### Alternativa 2: Permitir AMBOS (status quo)

**Rejeitada porque:**
- Inconsist√™ncia atual √© inaceit√°vel
- Imposs√≠vel fazer lint
- Confus√£o para novos desenvolvedores

### Alternativa 3: Usar dashmap::DashMap

**Rejeitada porque:**
- Lock-free √© overkill para nossa carga
- Adiciona depend√™ncia externa
- Complexidade sem benef√≠cio claro

## Refer√™ncias

- [Tokio Tutorial: Shared State](https://tokio.rs/tokio/tutorial/shared-state)
- [Rust Book: Fearless Concurrency](https://doc.rust-lang.org/book/ch16-00-concurrency.html)
- [Arc<RwLock<>> vs Arc<Mutex<>>](https://users.rust-lang.org/t/arc-mutex-vs-arc-rwlock/54972)

## Notas de Implementa√ß√£o

**Verifica√ß√£o de conformidade:**
```bash
./scripts/check_concurrency.sh
```

**Exce√ß√µes:**
- NENHUMA. Sem exce√ß√µes permitidas para StorageBackend.
- Outros componentes podem usar RwLock SE justificado (ex: cache read-heavy comprovado por profiling).

---

**Status de Implementa√ß√£o:** ‚è≥ Aguardando aprova√ß√£o
**Pr√≥ximo passo:** Executar Fase 1 (Prote√ß√£o)
